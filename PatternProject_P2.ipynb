{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb22653",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1608d",
   "metadata": {},
   "source": [
    "### Load COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = open('coco.names').read().strip().split('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265ea69",
   "metadata": {},
   "source": [
    "### Load Neural Netowrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg','yolov3.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffb572",
   "metadata": {},
   "source": [
    "### Getting Layer Names and Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f175e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = net.getLayerNames()\n",
    "outputlayers = list(net.getUnconnectedOutLayersNames())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b21dd3",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    H,W = image.shape[:2]   #height and width of the image\n",
    "    blob = cv2.dnn.blobFromImage(image,1/255.0,(416,416),crop=False,swapRB=False)  #preprocessing the image\n",
    "    net.setInput(blob)   #input the image to the network\n",
    "    layers_output = net.forward(outputlayers)  #forward path\n",
    "    \n",
    "    for output in layers_output:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]   #getting the scores of all the classes           \n",
    "            classID = np.argmax(scores)  #getting ID of the class that has maximum score\n",
    "            confidence = scores[classID]  #confidence of the class\n",
    "            \n",
    "            if confidence > 0.75:\n",
    "                box = detection[:4] * np.array([W,H,W,H])  #Getting center,width and height of the box\n",
    "                bx,by,bw,bh = box.astype(\"int\")   \n",
    "                x = int(bx-(bw/2))  # x-coordinate of top left corner point\n",
    "                y = int(by-(bh/2))  # y-coordinate of top left corner point\n",
    "                \n",
    "                boxes.append([x,y,int(bw),int(bh)])  #inserting the box coordinates in boxes\n",
    "                confidences.append(float(confidence)) #inserting confidence of the class in confidences\n",
    "                classIDs.append(classID)  #inserting class Index in ClassIDs\n",
    "                \n",
    "                \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.75,0.6) #Filtering boxes using non maximum suppression\n",
    "    \n",
    "    \n",
    "    #Using indices of filtered boxes to get their x,y,w,h\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y = [boxes[i][0],boxes[i][1]]  # top left corner point \n",
    "            w,h = [boxes[i][2],boxes[i][3]]  #width and height of the box\n",
    "            \n",
    "            #Drawing boxes\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,139,139),2)\n",
    "            \n",
    "            #Writing the prediction on the box\n",
    "            cv2.putText(image,\"{}: {}\".format(labels[classIDs[i]],confidences[i]),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,139,139),2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e451af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "final = clip.fl_image(process).subclip(30)\n",
    "%time final.write_videofile(\"x.mp4\", audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc8363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
